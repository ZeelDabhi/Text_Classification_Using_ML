{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","\n","import nltk \n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer\n","\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","import re\n","\n","print(\"Tensorflow Version\",tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv',\n","                 encoding = 'latin',header=None)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = df.drop(['id', 'date', 'query', 'user_id'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lab_to_sentiment = {0:\"Negative\", 4:\"Positive\"}\n","def label_decoder(label):\n","  return lab_to_sentiment[label]\n","df.sentiment = df.sentiment.apply(lambda x: label_decoder(x))\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_count = df.sentiment.value_counts()\n","\n","plt.figure(figsize=(8,4))\n","plt.bar(val_count.index, val_count.values)\n","plt.title(\"Sentiment Data Distribution\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","random_idx_list = [random.randint(1,len(df.text)) for i in range(10)] # creates random indexes to choose from dataframe\n","df.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stop_words = stopwords.words('english')\n","stemmer = SnowballStemmer('english')\n","\n","text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess(text, stem=False):\n","  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n","  tokens = []\n","  for token in text.split():\n","    if token not in stop_words:\n","      if stem:\n","        tokens.append(stemmer.stem(token))\n","      else:\n","        tokens.append(token)\n","  return \" \".join(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.text = df.text.apply(lambda x: preprocess(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from wordcloud import WordCloud\n","\n","plt.figure(figsize = (20,20)) \n","wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 'Positive'].text))\n","plt.imshow(wc , interpolation = 'bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (20,20)) \n","wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 'Negative'].text))\n","plt.imshow(wc , interpolation = 'bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["TRAIN_SIZE = 0.8\n","MAX_NB_WORDS = 100000\n","MAX_SEQUENCE_LENGTH = 30"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n","                                         random_state=7) # Splits Dataset into Training and Testing set\n","print(\"Train Data size:\", len(train_data))\n","print(\"Test Data size\", len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_data.text)\n","\n","word_index = tokenizer.word_index\n","vocab_size = len(tokenizer.word_index) + 1\n","print(\"Vocabulary Size :\", vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.text),\n","                        maxlen = MAX_SEQUENCE_LENGTH)\n","x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.text),\n","                       maxlen = MAX_SEQUENCE_LENGTH)\n","\n","print(\"Training X Shape:\",x_train.shape)\n","print(\"Testing X Shape:\",x_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels = train_data.sentiment.unique().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encoder = LabelEncoder()\n","encoder.fit(train_data.sentiment.to_list())\n","\n","y_train = encoder.transform(train_data.sentiment.to_list())\n","y_test = encoder.transform(test_data.sentiment.to_list())\n","\n","y_train = y_train.reshape(-1,1)\n","y_test = y_test.reshape(-1,1)\n","\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["GLOVE_EMB = '/kaggle/working/glove.6B.300d.txt'\n","EMBEDDING_DIM = 300\n","LR = 1e-3\n","BATCH_SIZE = 1024\n","EPOCHS = 10\n","MODEL_PATH = '.../output/kaggle/working/best_model.hdf5'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["embeddings_index = {}\n","\n","f = open(GLOVE_EMB)\n","for line in f:\n","  values = line.split()\n","  word = value = values[0]\n","  coefs = np.asarray(values[1:], dtype='float32')\n","  embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' %len(embeddings_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","  embedding_vector = embeddings_index.get(word)\n","  if embedding_vector is not None:\n","    embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["embedding_layer = tf.keras.layers.Embedding(vocab_size,\n","                                          EMBEDDING_DIM,\n","                                          weights=[embedding_matrix],\n","                                          input_length=MAX_SEQUENCE_LENGTH,\n","                                          trainable=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n","from tensorflow.keras.layers import SpatialDropout1D\n","from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedding_sequences = embedding_layer(sequence_input)\n","x = SpatialDropout1D(0.2)(embedding_sequences)\n","x = Conv1D(64, 5, activation='relu')(x)\n","x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(512, activation='relu')(x)\n","outputs = Dense(1, activation='sigmoid')(x)\n","model = tf.keras.Model(sequence_input, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","model.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\n","                                     min_lr = 0.01,\n","                                     monitor = 'val_loss',\n","                                     verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Training on GPU...\") if tf.test.is_gpu_available() else print(\"Training on CPU...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n","                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["s, (at, al) = plt.subplots(2,1)\n","at.plot(history.history['accuracy'], c= 'b')\n","at.plot(history.history['val_accuracy'], c='r')\n","at.set_title('model accuracy')\n","at.set_ylabel('accuracy')\n","at.set_xlabel('epoch')\n","at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n","\n","al.plot(history.history['loss'], c='m')\n","al.plot(history.history['val_loss'], c='c')\n","al.set_title('model loss')\n","al.set_ylabel('loss')\n","al.set_xlabel('epoch')\n","al.legend(['train', 'val'], loc = 'upper left')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def decode_sentiment(score):\n","    return \"Positive\" if score>0.5 else \"Negative\"\n","\n","\n","scores = model.predict(x_test, verbose=1, batch_size=10000)\n","y_pred_1d = [decode_sentiment(score) for score in scores]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import itertools\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","def plot_confusion_matrix(cm, classes,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","\n","    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize=20)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, fontsize=13)\n","    plt.yticks(tick_marks, classes, fontsize=13)\n","\n","    fmt = '.2f'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label', fontsize=17)\n","    plt.xlabel('Predicted label', fontsize=17)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cnf_matrix = confusion_matrix(test_data.sentiment.to_list(), y_pred_1d)\n","plt.figure(figsize=(6,6))\n","plot_confusion_matrix(cnf_matrix, classes=test_data.sentiment.unique(), title=\"Confusion matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(classification_report(list(test_data.sentiment), y_pred_1d))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
